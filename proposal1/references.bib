@article{2018AlzheimersDisease2018,
  title = {2018 {{Alzheimer}}'s Disease Facts and Figures},
  year = 2018,
  month = mar,
  journal = {Alzheimer's \& Dementia},
  volume = {14},
  number = {3},
  pages = {367--429},
  issn = {1552-5260},
  doi = {10.1016/j.jalz.2018.02.001},
  abstract = {This article describes the public health impact of Alzheimer's disease (AD), including incidence and prevalence, mortality and morbidity, costs of care, and the overall impact on caregivers and society. The Special Report examines the benefits of diagnosing Alzheimer's earlier in the disease process, in the stage of mild cognitive impairment due to Alzheimer's disease. An estimated 5.7~million Americans have Alzheimer's dementia. By mid-century, the number of people living with Alzheimer's dementia in the United States is projected to grow to 13.8 million, fueled in large part by the aging baby boom generation. In 2015, official death certificates recorded 110,561 deaths from AD, making AD the sixth leading cause of death in the United States and the fifth leading cause of death in Americans age {$\geq$}65~years. Between 2000 and 2015, deaths resulting from stroke, heart disease, and prostate cancer decreased, whereas deaths from AD increased 123\%. In 2017, more than 16 million family members and other unpaid caregivers provided an estimated 18.4 billion hours of care to people with Alzheimer's or other dementias. This care is valued at more than \$232 billion, but its costs extend to family caregivers' increased risk for emotional distress and negative mental and physical health outcomes. Average per-person Medicare payments for services to beneficiaries age {$\geq$}65~years with Alzheimer's or other dementias are more than three times as great as payments for beneficiaries without these conditions, and Medicaid payments are more than 23 times as great. Total payments in 2018 for health care, long-term care and hospice services for people age {$\geq$}65~years with dementia are estimated to be \$277 billion. With the identification of AD biomarkers in recent years, our understanding of the disease has moved from one based on symptoms to one based on brain changes. Because these changes begin well before clinical symptoms arise, Alzheimer's has the potential to be diagnosed before the dementia stage. Early diagnosis of AD could have important personal and financial benefits. A mathematical model estimates that early and accurate diagnosis could save up to \$7.9 trillion in medical and care costs.},
  keywords = {Alzheimer's dementia,Alzheimer's disease,Biomarker,Caregivers,Dementia,Diagnostic criteria,Early detection,Early diagnosis,Family caregiver,Health care costs,Health care expenditures,Health care professional,Incidence,Long-term care costs,Long-term care insurance,Medicaid spending,Medicare spending,Mild cognitive impairment,Morbidity,Mortality,Prevalence,Preventable hospitalizations,Risk factors,Spouse caregiver}
}

@misc{chatzichristodoulouMEDUSAMultimodalDeep2025,
  title = {{{MEDUSA}}: {{A Multimodal Deep Fusion Multi-Stage Training Framework}} for {{Speech Emotion Recognition}} in {{Naturalistic Conditions}}},
  shorttitle = {{{MEDUSA}}},
  author = {Chatzichristodoulou, Georgios and Kosmopoulou, Despoina and Kritikos, Antonios and Poulopoulou, Anastasia and Georgiou, Efthymios and Katsamanis, Athanasios and Katsouros, Vassilis and Potamianos, Alexandros},
  year = 2025,
  month = sep,
  number = {arXiv:2506.09556},
  eprint = {2506.09556},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2506.09556},
  abstract = {SER is a challenging task due to the subjective nature of human emotions and their uneven representation under naturalistic conditions. We propose MEDUSA, a multimodal framework with a four-stage training pipeline, which effectively handles class imbalance and emotion ambiguity. The first two stages train an ensemble of classifiers that utilize DeepSER, a novel extension of a deep cross-modal transformer fusion mechanism from pretrained self-supervised acoustic and linguistic representations. Manifold MixUp is employed for further regularization. The last two stages optimize a trainable meta-classifier that combines the ensemble predictions. Our training approach incorporates human annotation scores as soft targets, coupled with balanced data sampling and multitask learning. MEDUSA ranked 1st in Task 1: Categorical Emotion Recognition in the Interspeech 2025: Speech Emotion Recognition in Naturalistic Conditions Challenge.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@article{eybenGenevaMinimalisticAcoustic2016a,
  title = {The {{Geneva Minimalistic Acoustic Parameter Set}} ({{GeMAPS}}) for {{Voice Research}} and {{Affective Computing}}},
  author = {Eyben, Florian and Scherer, Klaus R. and Schuller, Bj{\"o}rn W. and Sundberg, Johan and Andr{\'e}, Elisabeth and Busso, Carlos and Devillers, Laurence Y. and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S. and Truong, Khiet P.},
  year = 2016,
  month = apr,
  journal = {IEEE Transactions on Affective Computing},
  volume = {7},
  number = {2},
  pages = {190--202},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2015.2457417},
  abstract = {Work on voice sciences over recent decades has led to a proliferation of acoustic parameters that are used quite selectively and are not always extracted in a similar fashion. With many independent teams working in different research areas, shared standards become an essential safeguard to ensure compliance with state-of-the-art methods allowing appropriate comparison of results across studies and potential integration and combination of extraction and recognition systems. In this paper we propose a basic standard acoustic parameter set for various areas of automatic voice analysis, such as paralinguistic or clinical speech analysis. In contrast to a large brute-force parameter set, we present a minimalistic set of voice parameters here. These were selected based on a) their potential to index affective physiological changes in voice production, b) their proven value in former studies as well as their automatic extractability, and c) their theoretical significance. The set is intended to provide a common baseline for evaluation of future research and eliminate differences caused by varying parameter sets or even different implementations of the same parameters. Our implementation is publicly available with the openSMILE toolkit. Comparative evaluations of the proposed feature set and large baseline feature sets of INTERSPEECH challenges show a high performance of the proposed set in relation to its size.},
  keywords = {acoustic features,Acoustic Features,Affective computing,Affective Computing,emotion recognition,Emotion Recognition,Frequency measurement,geneva minimalistic parameter set,Geneva Minimalistic Parameter Set,Harmonic analysis,Licenses,Mel frequency cepstral coefficient,Speech,speech analysis,Speech Analysis,standard,Standard,Standards}
}

@misc{gaoLeveragingMultimodalMethods2025,
  title = {Leveraging {{Multimodal Methods}} and {{Spontaneous Speech}} for {{Alzheimer}}'s {{Disease Identification}}},
  author = {Gao, Yifan and Guo, Long and Liu, Hong},
  year = 2025,
  month = feb,
  number = {arXiv:2412.09928},
  eprint = {2412.09928},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.09928},
  abstract = {Cognitive impairment detection through spontaneous speech is a promising avenue for early diagnosis of Alzheimer's disease (AD) and mild cognitive impairment (MCI), where timely intervention can significantly improve patient outcomes. The PROCESS Grand Challenge at ICASSP 2025 addresses these tasks by promoting innovative classification and regression methods for detecting cognitive decline. In this paper, we propose a multimodal fusion strategy that combines interpretable linguistic features with temporal embeddings extracted from pre-trained models. Our approach achieves an F1-score of 0.649 for the classification task (predicting healthy, MCI, dementia) and an RMSE of 2.628 for the regression task (MMSE score prediction), securing the top overall ranking in the competition.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
}

@inproceedings{georgiouDeepHierarchicalFusion2019,
  title = {Deep {{Hierarchical Fusion}} with {{Application}} in {{Sentiment Analysis}}},
  booktitle = {Interspeech 2019},
  author = {Georgiou, Efthymios and Papaioannou, Charilaos and Potamianos, Alexandros},
  year = 2019,
  month = sep,
  pages = {1646--1650},
  publisher = {ISCA},
  doi = {10.21437/Interspeech.2019-3243},
  abstract = {Recognizing the emotional tone in spoken language is a challenging research problem that requires modeling not only the acoustic and textual modalities separately but also their crossinteractions. In this work, we introduce a hierarchical fusion scheme for sentiment analysis of spoken sentences. Two bidirectional Long-Short-Term-Memory networks (BiLSTM), followed by multiple fully connected layers, are trained in order to extract feature representations for each of the textual and audio modalities. The representations of the unimodal encoders are both fused at each layer and propagated forward, thus achieving fusion at the word, sentence and high/sentiment levels. The proposed approach of deep hierarchical fusion achieves stateof-the-art results for sentiment analysis tasks. Through an ablation study, we show that the proposed fusion method achieves greater performance gains over the unimodal baseline compared to other fusion approaches in the literature.},
  langid = {english},
  keywords = {Sentiment Analysis}
}

@book{haiderAffectiveSpeechAlzheimers2020,
  title = {Affective {{Speech}} for {{Alzheimer}}'s {{Dementia Recognition}}},
  author = {Haider, Fasih and {de la Fuente Garcia}, Sofia and Albert, Pierre and Luz, Saturnino},
  year = 2020,
  month = may,
  abstract = {Affective behaviour could provide an indicator of Alzheimer's disease and help develop clinical tools for automatically detecting and monitoring disease progression. In this paper, we present a study of the predictive value of emotional behaviour features automatically extracted from spontaneous speech using an affect recognition system for Alzheimer's dementia detection. The effectiveness of affective behaviour features for Alzheimer's Disease detection was assessed on a gender and age balanced subset of the Pitt Corpus, a spontaneous speech database from DementiaBank. The affect recognition system was trained using the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) and the Berlin database of emotional speech. The output of this system provides classification scores or class posterior probabilities of 6+1 emotions as an input for statistical analysis and Alzheimer's dementia detection. The statistical analysis shows that the non-AD subjects have higher mean value of classification scores for anger and disgust, along with a higher entropy of classification scores than AD subjects. The AD subjects have a higher classification scores for the sad emotional behaviour than non-AD. This paper also introduces a novel 'affective behaviour representation' feature vector for Alzheimer's dementia recognition. Results show that classification models based solely on affective behaviour attain 63.42\% detection accuracy.}
}

@article{jiaWhisperBasedMultilingualAlzheimers,
  title = {Whisper-{{Based Multilingual Alzheimer}}'s {{Disease Detection}} and {{Improvements}} for {{Low-Resource Language}}},
  author = {Jia, Kaichen and Li, Jinpeng and Li, Ke and Zhang, Wei-Qiang},
  abstract = {Alzheimer's Disease (AD) poses a growing global health challenge due to population aging. Using spontaneous speech for the early diagnosis of AD has emerged as a notable area of research. In response to the global trend of AD, our study proposes a speech-based multilingual AD detection method. In our study, we utilize Whisper for transfer learning to build a multilingual pre-trained AD diagnostic model that achieves 81.38\% accuracy on a test set comprising multiple languages. To enhance low-resource language performance, we fine-tune the pre-trained model with multilingual data and full transcripts as prompts, achieving a 4-7\% accuracy improvement. Additionally, we incorporate the speaker's background information, enhancing the accuracy of low-resource languages by 11-13\%. The results demonstrate the validity of our work in multilingual Alzheimer's detection tasks and also illustrate the feasibility of our approach in addressing the global need for Alzheimer's detection.},
  langid = {english},
  keywords = {Fine-tuning}
}

@article{lanziDementiaBankTheoreticalRationale2023,
  title = {{{DementiaBank}}: {{Theoretical Rationale}}, {{Protocol}}, and {{Illustrative Analyses}}},
  shorttitle = {{{DementiaBank}}},
  author = {Lanzi, Alyssa M. and Saylor, Anna K. and Fromm, Davida and Liu, Houjun and MacWhinney, Brian and Cohen, Matthew L.},
  year = 2023,
  month = mar,
  journal = {American Journal of Speech-Language Pathology},
  volume = {32},
  number = {2},
  pages = {426--438},
  issn = {1058-0360},
  doi = {10.1044/2022_AJSLP-22-00281},
  abstract = {Purpose: Dementia from Alzheimer's disease (AD) is characterized primarily by a significant decline in memory abilities; however, language abilities are also commonly affected and may precede the decline of other cognitive abilities. To study the progression of language, there is a need for open-access databases that can be used to build algorithms to produce translational models sensitive enough to detect early declines in language abilities. DementiaBank is an open-access repository of transcribed video/audio data from communicative interactions from people with dementia, mild cognitive impairment (MCI), and controls. The aims of this tutorial are to (a) describe the newly established standardized DementiaBank discourse protocol, (b) describe the Delaware corpus data, and (c) provide examples of automated linguistic analyses that can be conducted with the Delaware corpus data and describe additional DementiaBank resources. Method: The DementiaBank discourse protocol elicits four types of discourse: picture description, story narrative, procedural, and personal narrative. The Delaware corpus currently includes data from 20 neurotypical adults and 33 adults with MCI from possible AD who completed the DementiaBank discourse protocol and a cognitive--linguistic battery. Language samples were video- and audio-recorded, transcribed, coded, and uploaded to DementiaBank. The protocol materials and transcription programs can be accessed for free via the DementiaBank website. Results: Illustrative analyses show the potential of the Delaware corpus data to help understand discourse metrics at the individual and group levels. In addition, they highlight analyses that could be used across TalkBank's other clinical banks (e.g., AphasiaBank). Information is also included on manual and automatic speech recognition transcription methods. Conclusions: DementiaBank is a shared online database that can facilitate research efforts to address the gaps in knowledge about language changes associated with MCI and dementia from AD. Identifying early language markers could lead to improved assessment and treatment approaches for adults at risk for dementia.},
  pmcid = {PMC10171844},
  pmid = {36791255}
}

@misc{liuCleverHansEffect2024,
  title = {Clever {{Hans Effect Found}} in {{Automatic Detection}} of {{Alzheimer}}'s {{Disease}} through {{Speech}}},
  author = {Liu, Yin-Long and Feng, Rui and Yuan, Jia-Hong and Ling, Zhen-Hua},
  year = 2024,
  month = jun,
  number = {arXiv:2406.07410},
  eprint = {2406.07410},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.07410},
  abstract = {We uncover an underlying bias present in the audio recordings produced from the picture description task of the Pitt corpus, the largest publicly accessible database for Alzheimer's Disease (AD) detection research. Even by solely utilizing the silent segments of these audio recordings, we achieve nearly 100\% accuracy in AD detection. However, employing the same methods to other datasets and preprocessed Pitt recordings results in typical levels (approximately 80\%) of AD detection accuracy. These results demonstrate a Clever Hans effect in AD detection on the Pitt corpus. Our findings emphasize the crucial importance of maintaining vigilance regarding inherent biases in datasets utilized for training deep learning models, and highlight the necessity for a better understanding of the models' performance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing}
}

@misc{luzAlzheimersDementiaRecognition2020,
  title = {Alzheimer's {{Dementia Recognition}} through {{Spontaneous Speech}}: {{The ADReSS Challenge}}},
  shorttitle = {Alzheimer's {{Dementia Recognition}} through {{Spontaneous Speech}}},
  author = {Luz, Saturnino and Haider, Fasih and de la Fuente, Sofia and Fromm, Davida and MacWhinney, Brian},
  year = 2020,
  month = aug,
  number = {arXiv:2004.06833},
  eprint = {2004.06833},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.06833},
  abstract = {The ADReSS Challenge at INTERSPEECH 2020 defines a shared task through which different approaches to the automated recognition of Alzheimer's dementia based on spontaneous speech can be compared. ADReSS provides researchers with a benchmark speech dataset which has been acoustically pre-processed and balanced in terms of age and gender, defining two cognitive assessment tasks, namely: the Alzheimer's speech classification task and the neuropsychological score regression task. In the Alzheimer's speech classification task, ADReSS challenge participants create models for classifying speech as dementia or healthy control speech. In the the neuropsychological score regression task, participants create models to predict mini-mental state examination scores. This paper describes the ADReSS Challenge in detail and presents a baseline for both tasks, including feature extraction procedures and results for classification and regression models. ADReSS aims to provide the speech and language Alzheimer's research community with a platform for comprehensive methodological comparisons. This will hopefully contribute to addressing the lack of standardisation that currently affects the field and shed light on avenues for future research and clinical applicability.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning}
}

@article{luzDetectingCognitiveDecline,
  title = {Detecting Cognitive Decline Using Speech Only: {{The ADReSSO Challenge}}},
  author = {Luz, Saturnino and Haider, Fasih},
  abstract = {Building on the success of the ADReSS Challenge at Interspeech 2020, which attracted the participation of 34 teams from across the world, the ADReSSo Challenge targets three difficult automatic prediction problems of societal and medical relevance, namely: detection of Alzheimer's Dementia, inference of cognitive testing scores, and prediction of cognitive decline. This paper presents these prediction tasks in detail, describes the datasets used, and reports the results of the baseline classification and regression models we developed for each task. A combination of acoustic and linguistic features extracted directly from audio recordings, without human intervention, yielded a baseline accuracy of 78.87\% for the AD classification task, a root mean squared (RMSE) error of 5.28 for prediction of cognitive scores , and 68.75\% accuracy for the cognitive decline prediction task.},
  langid = {english}
}

@article{luzOverviewADReSSMSignal2024,
  title = {An {{Overview}} of the {{ADReSS-M Signal Processing Grand Challenge}} on {{Multilingual Alzheimer}}'s {{Dementia Recognition Through Spontaneous Speech}}},
  author = {Luz, Saturnino and Haider, Fasih and Fromm, Davida and Lazarou, Ioulietta and Kompatsiaris, Ioannis and Macwhinney, Brian},
  year = 2024,
  month = mar,
  journal = {IEEE Open Journal of Signal Processing},
  volume = {PP},
  pages = {1--12},
  doi = {10.1109/OJSP.2024.3378595},
  abstract = {The ADReSS-M Signal Processing Grand Challenge was held at the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023. The challenge targeted difficult automatic prediction problems of great societal and medical relevance, namely, the detection of Alzheimer's Dementia (AD) and the estimation of cognitive test scoress. Participants were invited to create models for the assessment of cognitive function based on spontaneous speech data. Most of these models employed signal processing and machine learning methods. The ADReSS-M challenge was designed to assess the extent to which predictive models built based on speech in one language generalise to another language. The language data compiled and made available for ADReSS-M comprised English, for model training, and Greek, for model testing and validation. To the best of our knowledge no previous shared research task investigated acoustic features of the speech signal or linguistic characteristics in the context of multilingual AD detection. This paper describes the context of the ADReSS-M challenge, its data sets, its predictive tasks, the evaluation methodology we employed, our baseline models and results, and the top five submissions. The paper concludes with a summary discussion of the ADReSS-M results, and our critical assessment of the future outlook in this field.}
}

@article{nicholsEstimationGlobalPrevalence2022,
  title = {Estimation of the Global Prevalence of Dementia in 2019 and Forecasted Prevalence in 2050: An Analysis for the {{Global Burden}} of {{Disease Study}} 2019},
  shorttitle = {Estimation of the Global Prevalence of Dementia in 2019 and Forecasted Prevalence in 2050},
  author = {Nichols, Emma and Steinmetz, Jaimie D and Vollset, Stein Emil and Fukutaki, Kai and Chalek, Julian and {Abd-Allah}, Foad and Abdoli, Amir and Abualhasan, Ahmed and {Abu-Gharbieh}, Eman and Akram, Tayyaba Tayyaba and Al Hamad, Hanadi and Alahdab, Fares and Alanezi, Fahad Mashhour and Alipour, Vahid and Almustanyir, Sami and Amu, Hubert and Ansari, Iman and Arabloo, Jalal and Ashraf, Tahira and {Astell-Burt}, Thomas and Ayano, Getinet and {Ayuso-Mateos}, Jose L and Baig, Atif Amin and Barnett, Anthony and Barrow, Amadou and Baune, Bernhard T and B{\'e}jot, Yannick and Bezabhe, Woldesellassie M Mequanint and Bezabih, Yihienew Mequanint and Bhagavathula, Akshaya Srikanth and Bhaskar, Sonu and Bhattacharyya, Krittika and Bijani, Ali and Biswas, Atanu and Bolla, Srinivasa Rao and Boloor, Archith and Brayne, Carol and Brenner, Hermann and Burkart, Katrin and Burns, Richard A and C{\'a}mera, Luis Alberto and Cao, Chao and Carvalho, Felix and {Castro-de-Araujo}, Luis F S and {Catal{\'a}-L{\'o}pez}, Ferr{\'a}n and Cerin, Ester and Chavan, Prachi P and Cherbuin, Nicolas and Chu, Dinh-Toi and Costa, Vera Marisa and Couto, Rosa A S and Dadras, Omid and Dai, Xiaochen and Dandona, Lalit and Dandona, Rakhi and {De La Cruz-G{\'o}ngora}, Vanessa and Dhamnetiya, Deepak and Dias Da Silva, Diana and Diaz, Daniel and Douiri, Abdel and Edvardsson, David and Ekholuenetale, Michael and El Sayed, Iman and {El-Jaafary}, Shaimaa I and Eskandari, Khalil and Eskandarieh, Sharareh and Esmaeilnejad, Saman and Fares, Jawad and Faro, Andre and Farooque, Umar and Feigin, Valery L and Feng, Xiaoqi and Fereshtehnejad, Seyed-Mohammad and Fernandes, Eduarda and Ferrara, Pietro and Filip, Irina and Fillit, Howard and Fischer, Florian and Gaidhane, Shilpa and Galluzzo, Lucia and Ghashghaee, Ahmad and Ghith, Nermin and Gialluisi, Alessandro and Gilani, Syed Amir and Glavan, Ionela-Roxana and Gnedovskaya, Elena V and Golechha, Mahaveer and Gupta, Rajeev and Gupta, Veer Bala and Gupta, Vivek Kumar and Haider, Mohammad Rifat and Hall, Brian J and Hamidi, Samer and Hanif, Asif and Hankey, Graeme J and Haque, Shafiul and Hartono, Risky Kusuma and Hasaballah, Ahmed I and Hasan, M Tasdik and Hassan, Amr and Hay, Simon I and Hayat, Khezar and Hegazy, Mohamed I and Heidari, Golnaz and {Heidari-Soureshjani}, Reza and Herteliu, Claudiu and Househ, Mowafa and Hussain, Rabia and Hwang, Bing-Fang and Iacoviello, Licia and Iavicoli, Ivo and Ilesanmi, Olayinka Stephen and Ilic, Irena M and Ilic, Milena D and Irvani, Seyed Sina Naghibi and Iso, Hiroyasu and Iwagami, Masao and Jabbarinejad, Roxana and Jacob, Louis and Jain, Vardhmaan and Jayapal, Sathish Kumar and Jayawardena, Ranil and Jha, Ravi Prakash and Jonas, Jost B and Joseph, Nitin and Kalani, Rizwan and Kandel, Amit and Kandel, Himal and Karch, Andr{\'e} and Kasa, Ayele Semachew and Kassie, Gizat M and Keshavarz, Pedram and Khan, Moien Ab and Khatib, Mahalaqua Nazli and Khoja, Tawfik Ahmed Muthafer and Khubchandani, Jagdish and Kim, Min Seo and Kim, Yun Jin and Kisa, Adnan and Kisa, Sezer and Kivim{\"a}ki, Mika and Koroshetz, Walter J and Koyanagi, Ai and Kumar, G Anil and Kumar, Manasi and Lak, Hassan Mehmood and Leonardi, Matilde and Li, Bingyu and Lim, Stephen S and Liu, Xuefeng and Liu, Yuewei and Logroscino, Giancarlo and Lorkowski, Stefan and Lucchetti, Giancarlo and Lutzky Saute, Ricardo and Magnani, Francesca Giulia and Malik, Ahmad Azam and Massano, Jo{\~a}o and Mehndiratta, Man Mohan and Menezes, Ritesh G and Meretoja, Atte and Mohajer, Bahram and Mohamed Ibrahim, Norlinah and Mohammad, Yousef and Mohammed, Arif and Mokdad, Ali H and Mondello, Stefania and Moni, Mohammad Ali Ali and Moniruzzaman, Md and Mossie, Tilahun Belete and Nagel, Gabriele and Naveed, Muhammad and Nayak, Vinod C and Neupane Kandel, Sandhya and Nguyen, Trang Huyen and Oancea, Bogdan and Otstavnov, Nikita and Otstavnov, Stanislav S and Owolabi, Mayowa O and {Panda-Jonas}, Songhomitra and Pashazadeh Kan, Fatemeh and Pasovic, Maja and Patel, Urvish K and Pathak, Mona and Peres, Mario F P and Perianayagam, Arokiasamy and Peterson, Carrie B and Phillips, Michael R and Pinheiro, Marina and Piradov, Michael A and Pond, Constance Dimity and Potashman, Michele H and Pottoo, Faheem Hyder and Prada, Sergio I and Radfar, Amir and Raggi, Alberto and Rahim, Fakher and Rahman, Mosiur and Ram, Pradhum and Ranasinghe, Priyanga and Rawaf, David Laith and Rawaf, Salman and Rezaei, Nima and Rezapour, Aziz and Robinson, Stephen R and Romoli, Michele and Roshandel, Gholamreza and Sahathevan, Ramesh and Sahebkar, Amirhossein and Sahraian, Mohammad Ali and Sathian, Brijesh and Sattin, Davide and Sawhney, Monika and Saylan, Mete and Schiavolin, Silvia and Seylani, Allen and Sha, Feng and Shaikh, Masood Ali and Shaji, Ks and Shannawaz, Mohammed and Shetty, Jeevan K and Shigematsu, Mika and Shin, Jae Il and Shiri, Rahman and Silva, Diego Augusto Santos and Silva, Jo{\~a}o Pedro and Silva, Renata and Singh, Jasvinder A and Skryabin, Valentin Yurievich and Skryabina, Anna Aleksandrovna and Smith, Amanda E and Soshnikov, Sergey and Spurlock, Emma Elizabeth and Stein, Dan J and Sun, Jing and {Tabar{\'e}s-Seisdedos}, Rafael and Thakur, Bhaskar and Timalsina, Binod and {Tovani-Palone}, Marcos Roberto and Tran, Bach Xuan and Tsegaye, Gebiyaw Wudie and Valadan Tahbaz, Sahel and Valdez, Pascual R and Venketasubramanian, Narayanaswamy and Vlassov, Vasily and Vu, Giang Thu and Vu, Linh Gia and Wang, Yuan-Pang and Wimo, Anders and Winkler, Andrea Sylvia and Yadav, Lalit and Yahyazadeh Jabbari, Seyed Hossein and Yamagishi, Kazumasa and Yang, Lin and Yano, Yuichiro and Yonemoto, Naohiro and Yu, Chuanhua and Yunusa, Ismaeel and Zadey, Siddhesh and Zastrozhin, Mikhail Sergeevich and Zastrozhina, Anasthasia and Zhang, Zhi-Jiang and Murray, Christopher J L and Vos, Theo},
  year = 2022,
  month = feb,
  journal = {The Lancet Public Health},
  volume = {7},
  number = {2},
  pages = {e105-e125},
  issn = {24682667},
  doi = {10.1016/S2468-2667(21)00249-8},
  abstract = {Background Given the projected trends in population ageing and population growth, the number of people with dementia is expected to increase. In addition, strong evidence has emerged supporting the importance of potentially modifiable risk factors for dementia. Characterising the distribution and magnitude of anticipated growth is crucial for public health planning and resource prioritisation. This study aimed to improve on previous forecasts of dementia prevalence by producing country-level estimates and incorporating information on selected risk factors.},
  langid = {english}
}

@article{rundeOptimizationNaturalLanguage2024,
  title = {The {{Optimization}} of a {{Natural Language Processing Approach}} for the {{Automatic Detection}} of {{Alzheimer}}'s {{Disease Using GPT Embeddings}}},
  author = {Runde, Benjamin S. and Alapati, Ajit and Bazan, Nicolas G.},
  year = 2024,
  month = feb,
  journal = {Brain Sciences},
  volume = {14},
  number = {3},
  pages = {211},
  doi = {10.3390/brainsci14030211},
  abstract = {The development of noninvasive and cost-effective methods of detecting Alzheimer's disease (AD) is essential for its early prevention and mitigation. We optimize the detection of AD using natural language processing (NLP) of spontaneous speech ...},
  langid = {english},
  pmid = {38539600},
  keywords = {Data Augmentation,Fine-tuning}
}

@misc{shakeriMultiConADUnifiedMultilingual2025,
  title = {{{MultiConAD}}: {{A Unified Multilingual Conversational Dataset}} for {{Early Alzheimer}}'s {{Detection}}},
  shorttitle = {{{MultiConAD}}},
  author = {Shakeri, Arezo and Farmanbar, Mina and Balog, Krisztian},
  year = 2025,
  month = feb,
  number = {arXiv:2502.19208},
  eprint = {2502.19208},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.19208},
  abstract = {Dementia is a progressive cognitive syndrome with Alzheimer's disease (AD) as the leading cause. Conversation-based AD detection offers a cost-effective alternative to clinical methods, as language dysfunction is an early biomarker of AD. However, most prior research has framed AD detection as a binary classification problem, limiting the ability to identify Mild Cognitive Impairment (MCI)---a crucial stage for early intervention. Also, studies primarily rely on single-language datasets, mainly in English, restricting crosslanguage generalizability. To address this gap, we make three key contributions. First, we introduce a novel, multilingual dataset for AD detection by unifying 16 publicly available dementia-related conversational datasets. This corpus spans English, Spanish, Chinese, and Greek, and incorporates both audio and text data derived from a variety of cognitive assessment tasks. Second, we perform finer-grained classification, including MCI, and evaluate various classifiers using sparse and dense text representations. Third, we conduct experiments in monolingual and multilingual settings, finding that some languages benefit from multilingual training while others perform better independently. This study highlights the challenges in multilingual AD detection and enables future research on both language-specific approaches and techniques aimed at improving model generalization and robustness.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@article{shakeriNaturalLanguageProcessing2025a,
  title = {Natural Language Processing in {{Alzheimer}}'s Disease Research: {{Systematic}} Review of Methods, Data, and Efficacy},
  shorttitle = {Natural Language Processing in {{Alzheimer}}'s Disease Research},
  author = {Shakeri, Arezo and Farmanbar, Mina},
  year = 2025,
  month = feb,
  journal = {Alzheimer's \& Dementia : Diagnosis, Assessment \& Disease Monitoring},
  volume = {17},
  number = {1},
  pages = {e70082},
  issn = {2352-8729},
  doi = {10.1002/dad2.70082},
  abstract = {INTRODUCTION Alzheimer's disease (AD) prevalence is increasing, with no current cure. Natural language processing (NLP) offers the potential for non-invasive diagnostics, social burden assessment, and research advancements in~AD. METHOD A systematic review using Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines explored NLP applications in AD, focusing on dataset types, sources, research foci, methods, and effectiveness. Searches were conducted across six databases (ACM, Embase, IEEE, PubMed, Scopus, and Web of Science) from January 2020 to July~2024. RESULTS Of 1740 records, 79 studies were selected. Frequently used datasets included speech and electronic health records (EHR), along with social media and scientific publications. Machine learning and neural networks were primarily applied to speech, EHR, and social media data, while rule-based methods were used to analyze literature~datasets. DISCUSSION NLP has proven effective in various aspects of AD research, including diagnosis, monitoring, social burden assessment, biomarker analysis, and research. However, there are opportunities for improvement in dataset diversity, model interpretability, multilingual capabilities, and addressing ethical~concerns. Highlights This review systematically analyzed 79 studies from six major databases, focusing on the advancements and applications of natural language processing (NLP) in Alzheimer's disease (AD) research.The study highlights the need for models focusing on remote monitoring of AD patients using speech analysis, offering a cost-effective alternative to traditional methods such as brain imaging and aiding clinicians in both prediagnosis and post-diagnosis periods.The use of pretrained multilingual models is recommended to improve AD detection across different languages by leveraging diverse speech features and utilizing publicly available datasets.},
  pmcid = {PMC11812127},
  pmid = {39935888},
  keywords = {Review}
}

@article{silvaAlzheimersDiseaseRisk2019,
  title = {Alzheimer's Disease: Risk Factors and Potentially Protective Measures},
  shorttitle = {Alzheimer's Disease},
  author = {Silva, Marcos Vin{\'i}cius Ferreira and Loures, Cristina de Mello Gomide and Alves, Luan Carlos Vieira and {de Souza}, Leonardo Cruz and Borges, Karina Braga Gomes and Carvalho, Maria das Gra{\c c}as},
  year = 2019,
  month = may,
  journal = {Journal of Biomedical Science},
  volume = {26},
  pages = {33},
  issn = {1021-7770},
  doi = {10.1186/s12929-019-0524-y},
  abstract = {Alzheimer's disease (AD) is the most common type of dementia and typically manifests through a progressive loss of episodic memory and cognitive function, subsequently causing language and visuospatial skills deficiencies, which are often accompanied by behavioral disorders such as apathy, aggressiveness and depression. The presence of extracellular plaques of insoluble {$\beta$}-amyloid peptide (A{$\beta$}) and neurofibrillary tangles (NFT) containing hyperphosphorylated tau protein (P-tau) in the neuronal cytoplasm is a remarkable pathophysiological cause in patients' brains. Approximately 70\% of the risk of developing AD can be attributed to genetics. However, acquired factors such as cerebrovascular diseases, diabetes, hypertension, obesity and dyslipidemia increase the risk of AD development. The aim of the present minireview was to summarize the pathophysiological mechanism and the main risk factors for AD. As a complement, some protective factors associated with a lower risk of disease incidence, such as cognitive reserve, physical activity and diet will also be addressed.},
  pmcid = {PMC6507104},
  pmid = {31072403}
}

@misc{taoEarlyDementiaDetection2024,
  title = {Early {{Dementia Detection Using Multiple Spontaneous Speech Prompts}}: {{The PROCESS Challenge}}},
  shorttitle = {Early {{Dementia Detection Using Multiple Spontaneous Speech Prompts}}},
  author = {Tao, Fuxiang and Mirheidari, Bahman and Pahar, Madhurananda and Young, Sophie and Xiao, Yao and Elghazaly, Hend and Peters, Fritz and Illingworth, Caitlin and Braun, Dorota and O'Malley, Ronan and Bell, Simon and Blackburn, Daniel and Haider, Fasih and Luz, Saturnino and Christensen, Heidi},
  year = 2024,
  month = dec,
  number = {arXiv:2412.15230},
  eprint = {2412.15230},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.15230},
  abstract = {Dementia is associated with various cognitive impairments and typically manifests only after significant progression, making intervention at this stage often ineffective. To address this issue, the Prediction and Recognition of Cognitive Decline through Spontaneous Speech (PROCESS) Signal Processing Grand Challenge invites participants to focus on early-stage dementia detection. We provide a new spontaneous speech corpus for this challenge. This corpus includes answers from three prompts designed by neurologists to better capture the cognition of speakers. Our baseline models achieved an F1-score of 55.0\% on the classification task and an RMSE of 2.98 on the regression task.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
}

@misc{triantafyllopoulosDepressionDetectionSocial2023,
  title = {Depression Detection in Social Media Posts Using Affective and Social Norm Features},
  author = {Triantafyllopoulos, Ilias and Paraskevopoulos, Georgios and Potamianos, Alexandros},
  year = 2023,
  month = mar,
  number = {arXiv:2303.14279},
  eprint = {2303.14279},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.14279},
  abstract = {We propose a deep architecture for depression detection from social media posts. The proposed architecture builds upon BERT to extract language representations from social media posts and combines these representations using an attentive bidirectional GRU network. We incorporate affective information, by augmenting the text representations with features extracted from a pretrained emotion classifier. Motivated by psychological literature we propose to incorporate profanity and morality features of posts and words in our architecture using a late fusion scheme. Our analysis indicates that morality and profanity can be important features for depression detection. We apply our model for depression detection on Reddit posts on the Pirina dataset, and further consider the setting of detecting depressed users, given multiple posts per user, proposed in the Reddit RSDD dataset. The inclusion of the proposed features yields state-of-the-art results in both settings, namely 2.65\% and 6.73\% absolute improvement in F1 score respectively.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Depression Detection}
}

@misc{xezonakiAffectiveConditioningHierarchical2020a,
  title = {Affective {{Conditioning}} on {{Hierarchical Networks}} Applied to {{Depression Detection}} from {{Transcribed Clinical Interviews}}},
  author = {Xezonaki, D. and Paraskevopoulos, G. and Potamianos, A. and Narayanan, S.},
  year = 2020,
  month = jun,
  journal = {arXiv.org},
  abstract = {In this work we propose a machine learning model for depression detection from transcribed clinical interviews. Depression is a mental disorder that impacts not only the subject's mood but also the use of language. To this end we use a Hierarchical Attention Network to classify interviews of depressed subjects. We augment the attention layer of our model with a conditioning mechanism on linguistic features, extracted from affective lexica. Our analysis shows that individuals diagnosed with depression use affective language to a greater extent than not-depressed. Our experiments show that external affective information improves the performance of the proposed architecture in the General Psychotherapy Corpus and the DAIC-WoZ 2017 depression datasets, achieving state-of-the-art 71.6 and 68.6 F1 scores respectively.},
  howpublished = {https://arxiv.org/abs/2006.08336v1},
  langid = {english}
}

@inproceedings{zhangCognitiveDeclineDetection2025,
  title = {Cognitive {{Decline Detection}} Using {{DLB Extraction Pipelines}}},
  booktitle = {{{ICASSP}} 2025 - 2025 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Zhang, Shibingfeng and Khlif, Nadia and Ferro, Marcello and Gagliardi, Gloria and Tamburini, Fabio},
  year = 2025,
  month = apr,
  pages = {1--2},
  issn = {2379-190X},
  doi = {10.1109/ICASSP49660.2025.10890866},
  abstract = {The Prediction and Recognition of Cognitive Decline through Spontaneous Speech (PROCESS) Signal Processing Grand Challenge focuses on detecting dementia by analyzing spontaneous speech production. The challenge proposes a classification task to distinguish between subjects categorized as healthy controls, mild cognitive impairment, and dementia. Our team tackled this task by leveraging Digital Linguistic Biomarkers (DLBs) extracted from speech. Our system outperformed over 100 competing systems, earning us first place in the classification task.},
  keywords = {Acoustics,Biomarkers,cognitive decline,Dementia,digital linguistic biomarker,Feature extraction,Linguistics,Pipelines,Production,Signal processing,Speech enhancement,Speech recognition,speech signal processing}
}

@article{zolnooriADscreenSpeechProcessingbased2023,
  title = {{{ADscreen}}: {{A Speech Processing-based Screening System}} for {{Automatic Identification}} of {{Patients}} with {{Alzheimer}}'s {{Disease}} and {{Related Dementia}}},
  shorttitle = {{{ADscreen}}},
  author = {Zolnoori, Maryam and Zolnour, Ali and Topaz, Maxim},
  year = 2023,
  month = sep,
  journal = {Artificial intelligence in medicine},
  volume = {143},
  pages = {102624},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2023.102624},
  abstract = {Alzheimer's disease and related dementias (ADRD) present a looming public health crisis, affecting roughly 5 million people and 11\% of older adults in the United States. Despite nationwide efforts for timely diagnosis of patients with ADRD, more than 50\% of them are not diagnosed and unaware of their disease. To address this challenge, we developed ADscreen, an innovative speech-processing based ADRD screening algorithm for the protective identification of patients with ADRD. ADscreen consists of five major components: (i) noise reduction for reducing background noises from the audio-recorded patient speech, (ii) modeling the patient's ability in phonetic motor planning using acoustic parameters of the patient's voice, (iii) modeling the patient's ability in semantic and syntactic levels of language organization using linguistic parameters of the patient speech, (iv) extracting vocal and semantic psycholinguistic cues from the patient speech, and (v) building and evaluating the screening algorithm. To identify important speech parameters (features) associated with ADRD, we used the Joint Mutual Information Maximization (JMIM), an effective feature selection method for high dimensional, small sample size datasets. Modeling the relationship between speech parameters and the outcome variable (presence/absence of ADRD) was conducted using three different machine learning (ML) architectures with the capability of joining informative acoustic and linguistic with contextual word embedding vectors obtained from the DistilBERT (Bidirectional Encoder Representations from Transformers). We evaluated the performance of the ADscreen on an audio-recorded patients' speech (verbal description) for the Cookie-Theft picture description task, which is publicly available in the dementia databank. The joint fusion of acoustic and linguistic parameters with contextual word embedding vectors of DistilBERT achieved F1-score = 84.64 (standard deviation [std] = \textpm{} 3.58) and AUC-ROC = 92.53 (std = \textpm{} 3.34) for training dataset, and F1-score = 89.55 and AUC-ROC = 93.89 for the test dataset. In summary, ADscreen has a strong potential to be integrated with clinical workflow to address the need for an ADRD screening tool so that patients with cognitive impairment can receive appropriate and timely care.,},
  pmcid = {PMC10483114},
  pmid = {37673583}
}
